{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 0. Installing Libraries"
      ],
      "metadata": {
        "id": "5YyAchJGJWAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# keras and tensorflow version might be wrong, so we need to down/upgrade\n",
        "shell_call <- function(command, ...) {\n",
        "  result <- system(command, intern = TRUE, ...)\n",
        "  cat(paste0(result, collapse = \"\\n\"))\n",
        "}\n",
        "\n",
        "shell_call(\"pip install tensorflow==2.10.0 tensorflow-probability==0.16 keras==2.10.0\")"
      ],
      "metadata": {
        "id": "wehe_DIJyXSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if(!require(deepregression)){\n",
        "  install.packages(\"deepregression\")\n",
        "  library(deepregression)\n",
        "}\n",
        "# note: this also loads tensorflow and keras (both required in the folllowing)\n",
        "\n",
        "if (!require(\"imager\")) {\n",
        "  install.packages(\"imager\")\n",
        "  library(imager)\n",
        "}"
      ],
      "metadata": {
        "id": "KNeOtGRmAqNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Auto Differentiation using TensorFlow"
      ],
      "metadata": {
        "id": "FbF7LVvRCI4m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, a more simple example where we automatically calculate $\\frac{\\partial f(x)}{\\partial x}$ where $f(x) = x^2$."
      ],
      "metadata": {
        "id": "ArW1eK3dCiFw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggyy_SDD4IPh"
      },
      "outputs": [],
      "source": [
        "# Define a quadratic function f(x) = x^2\n",
        "# (or any other that is differentiable)\n",
        "f <- function(x) {\n",
        "  x^2\n",
        "}\n",
        "\n",
        "# Create a scalar variable\n",
        "x <- tf$Variable(3.0)\n",
        "\n",
        "# Record the operations to compute the gradient\n",
        "with(tf$GradientTape() %as% tape, {\n",
        "  y <- f(x)\n",
        "})\n",
        "\n",
        "# Compute the gradient of y with respect to x\n",
        "grad <- tape$gradient(y, x) # i.e. dy/dx\n",
        "\n",
        "# Output the gradient -> should be 2*x = 2*3 = 6\n",
        "print(grad$numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try a bit more complicated function and see if it still works..."
      ],
      "metadata": {
        "id": "MDLuHPWVCzD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f <- function(X) {\n",
        "  tf$sqrt(tf$reduce_sum(tf$sinh(X)^2))\n",
        "}\n",
        "\n",
        "# Create a 3D variable tensor (an array)\n",
        "X <- tf$Variable(array(c(1,2,3,4,5,6), dim=c(2,1,3)))\n",
        "\n",
        "# Record the operations with GradientTape\n",
        "with(tf$GradientTape() %as% tape, {\n",
        "  z <- f(X)\n",
        "})\n",
        "\n",
        "# Compute gradient\n",
        "grad_X <- tape$gradient(z, X)\n",
        "\n",
        "# Print the original 3D tensor and its gradient\n",
        "cat('Original 3D tensor X:\\n')\n",
        "print(X$numpy())\n",
        "cat('\\nGradient of f w.r.t. X:\\n')\n",
        "print(grad_X$numpy())"
      ],
      "metadata": {
        "id": "NMdVrq5TCG4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we just computed a derivative w.r.t. an array (!) with no effort."
      ],
      "metadata": {
        "id": "19H27izQD-8l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Example for Gradient Descent Optimization using the Gradient Tape"
      ],
      "metadata": {
        "id": "FuO2EG_4Efxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "library(tensorflow)\n",
        "\n",
        "# Define a quadratic function f(x) = x^2\n",
        "f <- function(theta) {\n",
        "  theta^2\n",
        "}\n",
        "\n",
        "# Create a scalar variable\n",
        "theta <- tf$Variable(5.0)\n",
        "\n",
        "# Define a learning rate\n",
        "lr <- 0.1\n",
        "\n",
        "# Perform gradient descent\n",
        "for (i in 1:10) {\n",
        "  with(tf$GradientTape() %as% tape, {\n",
        "    y <- f(theta)\n",
        "  })\n",
        "\n",
        "  # Compute the gradient of y with respect to theta\n",
        "  grad <- tape$gradient(y, theta)\n",
        "\n",
        "  # Update theta: theta <- theta - lr * grad\n",
        "  theta$assign_sub(lr * grad)\n",
        "\n",
        "  # Print the current theta and y\n",
        "  cat('Step', i, ':', 'theta =', theta$numpy(), ', y =', y$numpy(), '\\n')\n",
        "}\n"
      ],
      "metadata": {
        "id": "wZ4HkJVFAmre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Optimizing Neural Networks in `keras`"
      ],
      "metadata": {
        "id": "RWeKlx63Ff9E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We start with a Multi-layer perceptron (a network with fully connected layers)\n",
        "- We use the MNIST data as an example, which we first load (incl. in keras)\n"
      ],
      "metadata": {
        "id": "62qybdzsGidx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MNIST dataset\n",
        "mnist <- dataset_mnist()\n",
        "x_train <- mnist$train$x\n",
        "y_train <- mnist$train$y\n",
        "x_test <- mnist$test$x\n",
        "y_test <- mnist$test$y"
      ],
      "metadata": {
        "id": "vY4GWU0nGxy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can visualize the data e.g. as follows:"
      ],
      "metadata": {
        "id": "DFG_g25oG7Kv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose the first image\n",
        "img <- x_train[1,,]\n",
        "\n",
        "# Visualize the image\n",
        "image(t(apply(img, 2, rev)), col = grey.colors(255), axes = FALSE)"
      ],
      "metadata": {
        "id": "g-_jwtanG30U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we have not yet learned the details of convolutional layers, we start by\n",
        "converting the images into long vectors (i.e. we use every pixel as a feature)"
      ],
      "metadata": {
        "id": "6LxPCNE-HTFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the data\n",
        "x_train <- array_reshape(x_train, c(nrow(x_train), 784)) / 255\n",
        "x_test <- array_reshape(x_test, c(nrow(x_test), 784)) / 255\n",
        "y_train <- to_categorical(y_train, 10)\n",
        "y_test <- to_categorical(y_test, 10)"
      ],
      "metadata": {
        "id": "7WJYJ_1jIJyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now define the network and train it using the `keras` functionalities:\n",
        "- `keras_model_sequential`: sets up a very simply sequential model (i.e. one layers follows the other)\n",
        "- `compile`: compiles / initializes the model (computes gradients etc.)\n",
        "- `fit`: runs the optimization (loop over epochs, batches and update weights using the optimizer)"
      ],
      "metadata": {
        "id": "Gk1lyqOAILs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define MLP model\n",
        "model_mlp <- keras_model_sequential() %>%\n",
        "  layer_dense(units = 256, activation = 'relu', input_shape = c(784)) %>%\n",
        "  layer_dropout(rate = 0.4) %>%\n",
        "  layer_dense(units = 128, activation = 'relu') %>%\n",
        "  layer_dropout(rate = 0.3) %>%\n",
        "  layer_dense(units = 10, activation = 'softmax')\n",
        "\n",
        "# Compile the model\n",
        "model_mlp %>% compile(\n",
        "  loss = 'categorical_crossentropy',\n",
        "  optimizer = optimizer_adam(),\n",
        "  metrics = c('accuracy')\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history_mlp <- model_mlp %>% fit(\n",
        "  x_train, y_train, # the data required\n",
        "  epochs = 10, # only run for 10 epochs -- probably not enough\n",
        "  batch_size = 128, # batch size\n",
        "  validation_split = 0.2, # data percentage to validate model performance\n",
        "  verbose = FALSE # set to TRUE to see details\n",
        ")"
      ],
      "metadata": {
        "id": "A1lAfQWcFXla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can visualize the optimization process as follows:"
      ],
      "metadata": {
        "id": "c_fkvTXTIzHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot(history_mlp)"
      ],
      "metadata": {
        "id": "6SvPc1VqIw3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also evaluate the performance on an independent data set"
      ],
      "metadata": {
        "id": "nx3wzbMIJfsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate performance\n",
        "model_mlp %>% evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "G4EqM6iXIvY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Optimizing Statistical Models in Neural Networks"
      ],
      "metadata": {
        "id": "gxAANl0xJpJc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try to fit a logistic regression in a neural network and compare with `glm`"
      ],
      "metadata": {
        "id": "Afl1Xh3KKSvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset from UCI Machine Learning Repository\n",
        "url <- \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "data <- read.csv(url, header = FALSE)\n",
        "data[,1:8] <- lapply(data[,1:8], scale)\n",
        "\n",
        "# Rename columns\n",
        "names(data) <- c(\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\",\n",
        "                 \"BMI\", \"DiabetesPedigreeFunction\", \"Age\", \"Outcome\")\n",
        "\n",
        "# Using glm for logistic regression\n",
        "glm_model <- glm(Outcome ~ ., family = binomial(), data = data)\n",
        "\n",
        "# Predicting and evaluating\n",
        "probabilities_glm <- predict(glm_model, data, type = \"response\")\n",
        "coefs_glm <- coef(glm_model)\n"
      ],
      "metadata": {
        "id": "K2uxyl8fJonP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "x <- as.matrix(data[,1:8])\n",
        "y <- data$Outcome\n",
        "\n",
        "# Define a single-layer neural network\n",
        "model <- keras_model_sequential() %>%\n",
        "  layer_dense(units = 1, activation = \"sigmoid\", input_shape = ncol(x))\n",
        "\n",
        "# Compile the model\n",
        "model %>% compile(\n",
        "  optimizer = optimizer_rmsprop(),\n",
        "  loss = \"binary_crossentropy\",\n",
        "  metrics = c(\"accuracy\")\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model %>% fit(\n",
        "  x, y,\n",
        "  epochs = 200,\n",
        "  batch_size = 16,\n",
        "  validation_split = 0.2,\n",
        "  callbacks = list(\n",
        "    # this callback stops as soon as there\n",
        "    # is no improvement for 10 iterations\n",
        "    callback_early_stopping(patience = 10,\n",
        "    restore_best_weights = TRUE)\n",
        "  )\n",
        ")\n",
        "\n",
        "# Predicting and evaluating\n",
        "probabilities_nn <- model %>% predict(x)\n",
        "coefs_nn <- model$weights"
      ],
      "metadata": {
        "id": "G6ASq59uKm2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's first compare the predictions"
      ],
      "metadata": {
        "id": "3Q1WW1LTLDJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot(probabilities_glm ~ as.vector(probabilities_nn))"
      ],
      "metadata": {
        "id": "yoGjyletK_hU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "... and compare estimated coefficients"
      ],
      "metadata": {
        "id": "JQw-xj2llY5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rbind(\n",
        "  coefs_glm,\n",
        "  coefs_nn = c(unlist(lapply(coefs_nn, as.matrix)[c(2,1)]))\n",
        ")\n"
      ],
      "metadata": {
        "id": "18GUo6Y9LIYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Semi-Structured Networks"
      ],
      "metadata": {
        "id": "01rTaSvWn6vv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the AirBnB data"
      ],
      "metadata": {
        "id": "wrmr5hR_stnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url <- \"https://github.com/davidruegamer/airbnb/raw/main/munich_clean_text.RDS\"\n",
        "destfile <- file.path(getwd(), \"munich.RDS\")\n",
        "download.file(url, destfile, mode = \"wb\")\n",
        "airbnb <- readRDS(\"munich.RDS\")\n",
        "airbnb$days_since_last_review <- as.numeric(difftime(airbnb$date, airbnb$last_review))"
      ],
      "metadata": {
        "id": "IYUKwLqcn720"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if everything worked as intended..."
      ],
      "metadata": {
        "id": "gKsB73z3syDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "str(airbnb,1)"
      ],
      "metadata": {
        "id": "w5XyM18vsxdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's first fit a generalized additive model using in a neural network"
      ],
      "metadata": {
        "id": "IFgmy38Os7x0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mod_airbnb <- deepregression(y = airbnb$price,\n",
        "                             list_of_formulas = list(\n",
        "                               ~ bedrooms + room_type +\n",
        "                                 s(review_scores_rating),\n",
        "                               ~ 1\n",
        "                             ),\n",
        "                             data = airbnb)\n",
        "mod_airbnb %>% fit(epochs = 1000,\n",
        "                   early_stopping = TRUE,\n",
        "                   patience = 50,\n",
        "                   verbose = FALSE)"
      ],
      "metadata": {
        "id": "yS9TBk1Vsv7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can visualize the results by, e.g., calling the `plot` function:"
      ],
      "metadata": {
        "id": "SSK0JLBVtC8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot(mod_airbnb)"
      ],
      "metadata": {
        "id": "8jyPm3DItAl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "or looking at the estimated coefficients"
      ],
      "metadata": {
        "id": "BsivXQfstlUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coef(mod_airbnb)"
      ],
      "metadata": {
        "id": "yhooEgastoHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's process\n",
        "- load and pre-process images\n",
        "- and define suitable models\n",
        "\n",
        "for defining the semi-structured network that combines the GAM and a convolutional neural network"
      ],
      "metadata": {
        "id": "Ae4LxcKWtGVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## pictures\n",
        "url1 <- \"https://github.com/davidruegamer/deepregression_tutorial/raw/main/32_1.zip\"\n",
        "destfile <- file.path(getwd(), \"32_1.zip\")\n",
        "download.file(url1, destfile, mode = \"wb\")\n",
        "unzip(\"32_1.zip\")\n",
        "url2 <- \"https://github.com/davidruegamer/deepregression_tutorial/raw/main/32_2.zip\"\n",
        "destfile <- file.path(getwd(), \"32_2.zip\")\n",
        "download.file(url2, destfile, mode = \"wb\")\n",
        "unzip(\"32_2.zip\")"
      ],
      "metadata": {
        "id": "PSrgV1vitF0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "airbnb$image <- paste0(getwd(), \"/32/\", airbnb$id, \".jpg\")"
      ],
      "metadata": {
        "id": "gRwpeAJDu6Sy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code defines a simple convolutional neural network (CNN).\n",
        "We will talk about some of the details later. For now you can just use this as is."
      ],
      "metadata": {
        "id": "q54xKUWtu9vG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## -----------------------------------------------------------------------------------------------------\n",
        "cnn_block <- function(filters, kernel_size, pool_size, rate, input_shape = NULL){\n",
        "    function(x){\n",
        "      x %>%\n",
        "        layer_conv_2d(filters, kernel_size, padding = \"same\", input_shape = input_shape) %>%\n",
        "        layer_activation(activation = \"relu\") %>%\n",
        "        layer_batch_normalization() %>%\n",
        "        layer_max_pooling_2d(pool_size = pool_size) %>%\n",
        "        layer_dropout(rate = rate)\n",
        "    }\n",
        "  }\n",
        "\n",
        "\n",
        "## -----------------------------------------------------------------------------------------------------\n",
        "cnn <- cnn_block(filters = 16, kernel_size = c(3,3), pool_size = c(3,3), rate = 0.25,\n",
        "                 shape(200, 200, 3))\n",
        "deep_model_cnn <- function(x){\n",
        "    x %>%\n",
        "    cnn() %>%\n",
        "    layer_flatten() %>%\n",
        "    layer_dense(32) %>%\n",
        "    layer_activation(activation = \"relu\") %>%\n",
        "    layer_batch_normalization() %>%\n",
        "    layer_dropout(rate = 0.5) %>%\n",
        "    layer_dense(1)\n",
        "}\n"
      ],
      "metadata": {
        "id": "61shI27Au6Ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we define the semi-structured model using the previous deep network"
      ],
      "metadata": {
        "id": "djoV8JHtvLaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mod_cnn <- deepregression(\n",
        "  y = log(airbnb$price),\n",
        "  list_of_formulas = list(\n",
        "    ~1 + te(latitude, longitude) + # a spatial effect\n",
        "      deep_model_cnn(image), # a CNN for images\n",
        "    ~1),\n",
        "  data = airbnb,\n",
        "  list_of_deep_models = list(deep_model_cnn =\n",
        "    list(deep_model_cnn, c(200,200,3))),\n",
        "  optimizer = optimizer_adam(lr = 0.0001)\n",
        ")"
      ],
      "metadata": {
        "id": "OoBIFjaPuWDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fitting a deepregression model is similar to keras,\n",
        "# but with some more arguments\n",
        "mod_cnn %>% fit(\n",
        "  epochs = 2, # a small number for demonstration purposes\n",
        "  early_stopping = TRUE, # directly activate early stopping\n",
        "  patience = 5, # and set the patience\n",
        "  verbose = FALSE\n",
        ")"
      ],
      "metadata": {
        "id": "nL15H051vVTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now, e.g., check the spatial effect (result is not really meaningful though)"
      ],
      "metadata": {
        "id": "PAcaqJS9Fjn1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot(mod_cnn)"
      ],
      "metadata": {
        "id": "kSa9w-05vvTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or make predictions for some pictures:"
      ],
      "metadata": {
        "id": "yEWltAQ5Fi_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image <- load.image(paste0(getwd(), \"/32/\", airbnb$id[1], \".jpg\"))\n",
        "plot(image)"
      ],
      "metadata": {
        "id": "og6XcCM7FhuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the corresponding prediction\n",
        "summary(log(airbnb$price))\n",
        "mod_cnn %>% predict(lapply(airbnb[c(\"image\", \"latitude\", \"longitude\")],\n",
        "                    \"[[\", 1))"
      ],
      "metadata": {
        "id": "67tl7NJZGRQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(mod_cnn %>% fitted() ~ log(airbnb$price))"
      ],
      "metadata": {
        "id": "b3FxRqQeXmNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Convolutional Layers"
      ],
      "metadata": {
        "id": "vC2Hbt2N3t85"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's implement the Sobel filter (only it's horizontal part for demonstration) in a keras network!"
      ],
      "metadata": {
        "id": "O36-EviH6qx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Sobel filter kernel for horizontal edge detection\n",
        "sobel_horizontal <- array(c(-1, 0, 1,\n",
        "                            -2, 0, 2,\n",
        "                            -1, 0, 1), dim = c(3, 3, 1, 1))\n",
        "\n",
        "# Building the model\n",
        "model <- keras_model_sequential() %>%\n",
        "  layer_conv_2d(filters = 1, kernel_size = c(3,3), input_shape = c(32,32,1),\n",
        "                use_bias = FALSE, activation = \"relu\",\n",
        "                # plug in the filter values -> normally we would learn these\n",
        "                # in a data-driven fashion!\n",
        "                kernel_initializer = initializer_constant(\n",
        "                  value = sobel_horizontal)\n",
        "               )"
      ],
      "metadata": {
        "id": "9afcq6Ui3w35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's apply the model / filter to an image and see the result:"
      ],
      "metadata": {
        "id": "I-qglLrZ4PZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load some examplary data (CIFAR10)\n",
        "cifar10 <- dataset_cifar10()\n",
        "x_train <- cifar10$train$x\n",
        "\n",
        "# Take one image\n",
        "img <- x_train[2,,,]\n",
        "img <- array_reshape(img, c(32,32,3))"
      ],
      "metadata": {
        "id": "IfJMs_mvLBAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the image to grayscale using imager\n",
        "img_imager <- as.cimg(img)\n",
        "img_gray <- grayscale(img_imager)\n",
        "\n",
        "# Apply the filter to the image\n",
        "edge_detected_image <- model %>% predict(\n",
        "  array_reshape(img_gray/255, c(1, 32, 32, 1)))\n",
        "\n",
        "# Plotting using imager\n",
        "layout(matrix(1:3, nrow = 1))\n",
        "plot(img_imager, axes=FALSE, main=\"Original Image\")\n",
        "plot(img_gray, axes=FALSE, main=\"Gray Image\")\n",
        "\n",
        "# Convert the prediction result to an imager image object for plotting\n",
        "edge_detected_imager <- as.cimg(edge_detected_image[1,,,])\n",
        "\n",
        "# Plotting the edge-detected image using imager\n",
        "plot(edge_detected_imager, axes=FALSE, main=\"Edge Detected Image\")"
      ],
      "metadata": {
        "id": "6OXAwOGX4SZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Recurrent Neural Networks"
      ],
      "metadata": {
        "id": "aig16gqR6ljv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's simulate a small time series and try to predict the next value using a seq-to-one RNN network!"
      ],
      "metadata": {
        "id": "oJaS9ZBu6pMl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, generate some synthetic data and plot it:"
      ],
      "metadata": {
        "id": "X-5cx14N690o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seed for reproducibility\n",
        "set.seed(123)\n",
        "\n",
        "# Generate synthetic time series\n",
        "seq_len <- 1000  # Length of the sequence\n",
        "x <- seq(1, seq_len)\n",
        "data <- x/200 + sin(2*pi*x/50) + rnorm(seq_len, sd=0.5)\n",
        "\n",
        "# Plot original data\n",
        "plot(x, data, type=\"l\", xlab=\"Time\", ylab=\"Value\", main=\"Synthetic Time Series\")"
      ],
      "metadata": {
        "id": "GxSFNxN26n7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we prepare the data for model fitting"
      ],
      "metadata": {
        "id": "yCIRM7Hm7Cjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "window_size <- 10  # Consider 10 time steps to predict the next one\n",
        "x_data <- NULL\n",
        "y_data <- NULL\n",
        "\n",
        "for (i in 1:(seq_len - window_size)) {\n",
        "  x_data <- rbind(x_data, data[i:(i + window_size - 1)])\n",
        "  y_data <- c(y_data, data[i + window_size])\n",
        "}\n",
        "\n",
        "# Reshape data for RNN\n",
        "x_data <- array_reshape(x_data, c(dim(x_data), 1))\n",
        "y_data <- array_reshape(y_data, c(length(y_data), 1))\n"
      ],
      "metadata": {
        "id": "2UcQKVij7GvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we define our RNN model. We'll use an LSTM layer which is usually better at capturing long-term dependencies than a simple RNN."
      ],
      "metadata": {
        "id": "AgI7UhlG7J0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model <- keras_model_sequential() %>%\n",
        "  layer_lstm(units = 50, input_shape = list(window_size, 1)) %>%\n",
        "  layer_dense(units = 1)\n",
        "\n",
        "model %>% compile(\n",
        "  optimizer = optimizer_adam(lr = 0.001),\n",
        "  loss = \"mean_squared_error\"\n",
        ")\n",
        "\n",
        "summary(model)\n",
        "\n",
        "### and train the model\n",
        "history <- model %>% fit(\n",
        "  x_data, y_data,\n",
        "  epochs = 100, batch_size = 20,\n",
        "  validation_split = 0.2,\n",
        "  shuffle = TRUE\n",
        ")\n",
        "\n",
        "# Plotting loss\n",
        "plot(history)\n"
      ],
      "metadata": {
        "id": "Pdu0TgZh7I3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we check how well we can predict:"
      ],
      "metadata": {
        "id": "cT5HrpOh7WfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_val <- model %>% predict(x_data)\n",
        "\n",
        "# Plotting\n",
        "par(mfrow = c(1, 1))\n",
        "plot(x, data, type=\"l\", xlab=\"Time\", ylab=\"Value\", main=\"Original and Predicted Time Series\")\n",
        "lines(11:1000, pred_val, col=\"red\")"
      ],
      "metadata": {
        "id": "CElRsXzx7Y9U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}